# Model definitions for kindle-to-anki
# Add/modify models here. Changes take effect on next app restart.
#
# Required fields:
#   id: Model identifier used by the API (e.g. "gpt-5-mini")
#   platform_id: Platform name ("openai", "grok", "gemini", "deepl")
#   family: "chat_completion", "embedding", or "translation"
#   quality_tier: "low", "medium", or "high"
#   encoding: Token encoding name (e.g. "o200k_base", "cl100k_base")
#
# Optional fields:
#   supports_json: true/false - Whether model supports JSON output mode
#   input_token_cost_per_1m: Cost in USD per 1M input tokens
#   output_token_cost_per_1m: Cost in USD per 1M output tokens
#   typical_latency_ms: Expected response latency in milliseconds
#   rpm_limit: Requests per minute limit
#   tpm_limit: Tokens per minute limit
#   rpd_limit: Requests per day limit
#   notes: Any additional notes

models:
  - id: gpt-5-mini
    platform_id: openai
    family: chat_completion
    quality_tier: medium
    encoding: o200k_base
    supports_json: true
    input_token_cost_per_1m: 0.25
    output_token_cost_per_1m: 2.00
    typical_latency_ms: 600

  - id: gpt-5.1
    platform_id: openai
    family: chat_completion
    quality_tier: high
    encoding: o200k_base
    supports_json: true
    input_token_cost_per_1m: 1.25
    output_token_cost_per_1m: 10.00
    typical_latency_ms: 900

  - id: grok-4
    platform_id: grok
    family: chat_completion
    quality_tier: high
    encoding: cl100k_base
    supports_json: true
    input_token_cost_per_1m: 3.00
    output_token_cost_per_1m: 15.00
    typical_latency_ms: 800

  - id: grok-3-mini
    platform_id: grok
    family: chat_completion
    quality_tier: medium
    encoding: cl100k_base
    supports_json: true
    input_token_cost_per_1m: 0.30
    output_token_cost_per_1m: 0.50
    typical_latency_ms: 500

  - id: gemini-3-flash-preview
    platform_id: gemini
    family: chat_completion
    quality_tier: medium
    encoding: cl100k_base
    supports_json: true
    input_token_cost_per_1m: 0.00
    output_token_cost_per_1m: 0.00
    typical_latency_ms: 700
    rpm_limit: 10
    tpm_limit: 250000
    rpd_limit: 1500

  - id: gemini-3-pro-preview
    platform_id: gemini
    family: chat_completion
    quality_tier: high
    encoding: cl100k_base
    supports_json: true
    input_token_cost_per_1m: 2.00
    output_token_cost_per_1m: 12.00
    typical_latency_ms: 1000

  - id: gemini-2.5-flash
    platform_id: gemini
    family: chat_completion
    quality_tier: medium
    encoding: cl100k_base
    supports_json: true
    input_token_cost_per_1m: 0.00
    output_token_cost_per_1m: 0.00
    typical_latency_ms: 500
    rpm_limit: 10
    tpm_limit: 250000
    rpd_limit: 1500

  - id: gemini-2.0-flash
    platform_id: gemini
    family: chat_completion
    quality_tier: medium
    encoding: cl100k_base
    supports_json: true
    input_token_cost_per_1m: 0.00
    output_token_cost_per_1m: 0.00
    typical_latency_ms: 400
    rpm_limit: 10
    tpm_limit: 250000
    rpd_limit: 1500
